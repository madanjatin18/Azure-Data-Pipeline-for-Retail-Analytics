{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a30253d3-045e-4aa7-997d-0160b587d6cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: True"
     ]
    }
   ],
   "source": [
    "# Define the authentication configuration\n",
    "configs = {\n",
    "  \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "  \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "# Mount the ADLS Gen2 container to Databricks\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://ds-project1@projectdatajatin.dfs.core.windows.net/\",\n",
    "  mount_point = \"/mnt/ds-project1\",\n",
    "  extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "269048ad-6998-4034-8b45-d1ef311ce7d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: [FileInfo(path='dbfs:/mnt/ds-project1/SalesLT/Address/', name='Address/', size=0, modificationTime=1719204770000),\n FileInfo(path='dbfs:/mnt/ds-project1/SalesLT/Customer/', name='Customer/', size=0, modificationTime=1719204773000),\n FileInfo(path='dbfs:/mnt/ds-project1/SalesLT/CustomerAddress/', name='CustomerAddress/', size=0, modificationTime=1719204769000),\n FileInfo(path='dbfs:/mnt/ds-project1/SalesLT/Product/', name='Product/', size=0, modificationTime=1719204777000),\n FileInfo(path='dbfs:/mnt/ds-project1/SalesLT/ProductCategory/', name='ProductCategory/', size=0, modificationTime=1719204769000),\n FileInfo(path='dbfs:/mnt/ds-project1/SalesLT/ProductDescription/', name='ProductDescription/', size=0, modificationTime=1719204774000),\n FileInfo(path='dbfs:/mnt/ds-project1/SalesLT/ProductModel/', name='ProductModel/', size=0, modificationTime=1719204771000),\n FileInfo(path='dbfs:/mnt/ds-project1/SalesLT/ProductModelProductDescription/', name='ProductModelProductDescription/', size=0, modificationTime=1719204769000),\n FileInfo(path='dbfs:/mnt/ds-project1/SalesLT/SalesOrderDetail/', name='SalesOrderDetail/', size=0, modificationTime=1719204776000),\n FileInfo(path='dbfs:/mnt/ds-project1/SalesLT/SalesOrderHeader/', name='SalesOrderHeader/', size=0, modificationTime=1719204773000)]"
     ]
    }
   ],
   "source": [
    "# Verify the mount\n",
    "dbutils.fs.ls(\"/mnt/ds-project1/SalesLT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d6bcc58-65a2-4df1-b5c5-e9d068fa7732",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: True"
     ]
    }
   ],
   "source": [
    "# Define the authentication configuration\n",
    "configs = {\n",
    "  \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "  \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "# Mount the ADLS Gen2 container to Databricks\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://ds-project1-silver@projectdatajatin.dfs.core.windows.net/\",\n",
    "  mount_point = \"/mnt/ds-project1-silver\",\n",
    "  extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cfc5821-6b2e-4800-84d2-3aed4175468c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: True"
     ]
    }
   ],
   "source": [
    "# Define the authentication configuration\n",
    "configs = {\n",
    "  \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "  \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "# Mount the ADLS Gen2 container to Databricks\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://ds-project1-gold@projectdatajatin.dfs.core.windows.net/\",\n",
    "  mount_point = \"/mnt/ds-project1-gold\",\n",
    "  extra_configs = configs)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "storageamount",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
